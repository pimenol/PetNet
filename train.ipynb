{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f7b15f-f312-483a-b6c7-3a83b0d6ef92",
   "metadata": {},
   "source": [
    "# Defining a custom dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274723a-8e9c-4e79-a8aa-6f1176d6f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "\n",
    "from model import PetsDataset\n",
    "from torchvision.utils import make_grid\n",
    "from model import Net\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "DEVICE_NAME = \"cpu\" if os.environ[\"CUDA_VISIBLE_DEVICES\"] == \"\" else \"cuda\"\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.dev.dszn.cz:3128\"\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://proxy.dev.dszn.cz:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.dev.dszn.cz:3128\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://proxy.dev.dszn.cz:3128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117b653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size_train': 32, 'batch_size_eval': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import get_config\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbe153",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eae20c-3b8b-4bcb-b881-61840d4668e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PetsDataset(config['dataset_path'])\n",
    "\n",
    "trainset_size = int(len(dataset) - config['val_set_coef'] * len(dataset))\n",
    "trainset, validset = torch.utils.data.random_split(dataset, [trainset_size, len(dataset) - trainset_size])\n",
    "print(f\"trainset_sz={len(trainset)}, validset_sz={len(validset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279eb4d-f92e-4f14-b132-ed4ac97bfa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=config['batch_size_train'], shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(validset, batch_size=config['batch_size_eval'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28182e61-4836-4128-95c1-2ca870fa232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,s,b, mask = next(iter(train_loader))\n",
    "x.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13aa0df-1026-4194-aa0d-004361bca296",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)\n",
    "mask = mask.to(device)\n",
    "to_viz = torch.cat([x, mask_to_img(mask)], dim=0)\n",
    "\n",
    "imshow(make_grid(to_viz))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc201aed-830b-4b72-a059-7e5dedda0d2a",
   "metadata": {},
   "source": [
    "# PyTorch LEGO (for segmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a326a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=config['patience'], factor=config['factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ff404",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_loss_fn = nn.CrossEntropyLoss()     \n",
    "species_loss_fn = nn.CrossEntropyLoss()      \n",
    "breed_loss_fn = nn.CrossEntropyLoss()         \n",
    "\n",
    "def combined_loss(seg_pred, seg_target, species_pred, species_target, breed_pred, breed_target, alpha=1.0, beta=1.0):\n",
    "    seg_ce = seg_loss_fn(seg_pred, seg_target)\n",
    "    seg_dice = dice_loss(seg_pred, seg_target)\n",
    "    seg_loss = seg_ce + seg_dice\n",
    "\n",
    "    species_loss = species_loss_fn(species_pred, species_target)\n",
    "\n",
    "    breed_loss = breed_loss_fn(breed_pred, breed_target)\n",
    "\n",
    "    total_loss = seg_loss + alpha * species_loss + beta * breed_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca10553",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = config['epoch']\n",
    "best_mean_iou = 0.0\n",
    "min_delta = 0.001\n",
    "epochs_no_improve = 0\n",
    "patience = 5\n",
    "\n",
    "model.breed_idx2name = dataset.breed_idx2name\n",
    "model.breed_name2idx = dataset.breed_name2idx\n",
    "model.cat_breed_names = dataset.cat_breed_names\n",
    "model.dog_breed_names = dataset.dog_breed_names\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for images, species, breed, masks in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "        images, species, breed, masks = images.to(device), species.to(device), breed.to(device), masks.to(device)\n",
    "\n",
    "        sp_pred, br_pred, seg_pred = model(images)\n",
    "\n",
    "        loss_sp = species_loss_fn(sp_pred, species)\n",
    "        loss_br = breed_loss_fn(br_pred, breed)\n",
    "        loss_seg = seg_loss_fn(seg_pred, masks)\n",
    "        loss = combined_loss(seg_pred, masks, sp_pred, species, br_pred, breed)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    species_acc_sum = 0.0\n",
    "    breed_top3_acc_count = 0\n",
    "    ious = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, species, breed, masks in valid_loader:\n",
    "            images, species, breed, masks = images.to(device), species.to(device), breed.to(device), masks.to(device)\n",
    "            \n",
    "            species_pred_str, top3_breeds_str, seg_pred_class = model.predict(images)\n",
    "            seg_pred_class = seg_pred_class.to(device)\n",
    "\n",
    "            species_map = {'dog': 0, 'cat': 1}\n",
    "            species_preds_idx = torch.tensor(species_map[species_pred_str]).to(device)\n",
    "\n",
    "            species_acc_sum += accuracy(species_preds_idx, species)\n",
    "\n",
    "\n",
    "            top3_breeds_indices = []\n",
    "            for bnames in top3_breeds_str:\n",
    "                idxs = model.breed_name2idx[bnames]\n",
    "                top3_breeds_indices.append(idxs)\n",
    "\n",
    "            breed_top3_acc_count += breed.item() in top3_breeds_indices\n",
    "\n",
    "            seg_classes = [0, 1, 2]\n",
    "            img_ious = []\n",
    "            for c in seg_classes:\n",
    "                _, _, iou_c = compute_seg_metrics(seg_pred_class, masks, c)\n",
    "                img_ious.append(iou_c)\n",
    "            ious.append(np.mean([iou.cpu().numpy() for iou in img_ious]))\n",
    "\n",
    "        species_acc = species_acc_sum / len(valid_loader)\n",
    "        breed_top3_acc = breed_top3_acc_count / len(valid_loader)\n",
    "        mean_iou = np.mean(ious)\n",
    "        print(f\"Epoch {epoch+1}: Species Acc: {species_acc:.2f}, Breed Top-3 Acc: {breed_top3_acc:.2f}, Mean IoU: {mean_iou:.2f}\")\n",
    "    if mean_iou - best_mean_iou > min_delta:\n",
    "        best_mean_iou = mean_iou\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(best_model_wts, \"best_weights.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement in Mean IoU for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    scheduler.step(mean_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9da96",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "species_acc_sum = 0.0\n",
    "breed_top3_acc_count = 0\n",
    "ious = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, species, breed, masks in valid_loader:\n",
    "        images, species, breed, masks = images.to(device), species.to(device), breed.to(device), masks.to(device)\n",
    "        \n",
    "        species_pred_str, top3_breeds_str, seg_pred_class = model.predict(images)\n",
    "        seg_pred_class = seg_pred_class.to(device)\n",
    "\n",
    "        species_map = {'dog': 0, 'cat': 1}\n",
    "        species_preds_idx = torch.tensor(species_map[species_pred_str]).to(device)\n",
    "\n",
    "        species_acc_sum += accuracy(species_preds_idx, species)\n",
    "\n",
    "\n",
    "        top3_breeds_indices = []\n",
    "        for bnames in top3_breeds_str:\n",
    "            idxs = model.breed_name2idx[bnames]\n",
    "            top3_breeds_indices.append(idxs)\n",
    "\n",
    "        breed_top3_acc_count += breed.item() in top3_breeds_indices\n",
    "\n",
    "        seg_classes = [0, 1, 2]\n",
    "        img_ious = []\n",
    "        for c in seg_classes:\n",
    "            _, _, iou_c = compute_seg_metrics(seg_pred_class, masks, c)\n",
    "            img_ious.append(iou_c)\n",
    "        ious.append(np.mean([iou.cpu().numpy() for iou in img_ious]))\n",
    "\n",
    "    species_acc = species_acc_sum / len(valid_loader)\n",
    "    breed_top3_acc = breed_top3_acc_count / len(valid_loader)\n",
    "    mean_iou = np.mean(ious)\n",
    "    print(f\"Epoch {epoch+1}: Species Acc: {species_acc:.2f}, Breed Top-3 Acc: {breed_top3_acc:.2f}, Mean IoU: {mean_iou:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cat_breed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22279464",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, species, breed, masks = next(iter(valid_loader))\n",
    "images, species, breed, masks = images.to(device), species.to(device), breed.to(device), masks.to(device)\n",
    "\n",
    "model.predict(images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
